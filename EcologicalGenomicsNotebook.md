# Title

## Author: Alison Hall
### Affiliation:
### E-mail contact: alison.hall@uvm.edu

### Start Date: 2020-01-13
### End Date: 2020-05-08
### Project Descriptions:   Ecological Genomics





# Table of Contents:
* [Entry 1: 2020-01-13, Monday](#id-)
* [Entry 2: 2020-01-14, Tuesday](#id-section2)
* [Entry 3: 2020-01-15, Wednesday](#id-section3)
* [Entry 4: 2020-01-16, Thursday](#id-section4)
* [Entry 5: 2020-01-17, Friday](#id-section5)
* [Entry 6: 2020-01-20, Monday](#id-section6)
* [Entry 7: 2020-01-21, Tuesday](#id-section7)
* [Entry 8: 2020-01-22, Wednesday](#id-Command Line)
* [Entry 9: 2020-01-23, Thursday](#id-section9)
* [Entry 10: 2020-01-24, Friday](#id-section10)
* [Entry 11: 2020-01-27, Monday](#id-section11)
* [Entry 12: 2020-01-28, Tuesday](#id-section12)
* [Entry 13: 2020-01-29, Wednesday](#Population Genetics Day One)
* [Entry 14: 2020-01-30, Thursday](#id-section14)
* [Entry 15: 2020-01-31, Friday](#id-section15)
* [Entry 16: 2020-02-03, Monday](#id-section16)
* [Entry 17: 2020-02-04, Tuesday](#id-section17)
* [Entry 18: 2020-02-05, Wednesday](#id-section18)
* [Entry 19: 2020-02-06, Thursday](#id-section19)
* [Entry 20: 2020-02-07, Friday](#id-section20)
* [Entry 21: 2020-02-10, Monday](#id-section21)
* [Entry 22: 2020-02-11, Tuesday](#id-section22)
* [Entry 23: 2020-02-12, Wednesday](#id-section23)
* [Entry 24: 2020-02-13, Thursday](#id-section24)
* [Entry 25: 2020-02-14, Friday](#id-section25)
* [Entry 26: 2020-02-17, Monday](#id-section26)
* [Entry 27: 2020-02-18, Tuesday](#id-section27)
* [Entry 28: 2020-02-19, Wednesday](#id-section28)
* [Entry 29: 2020-02-20, Thursday](#id-section29)
* [Entry 30: 2020-02-21, Friday](#id-section30)
* [Entry 31: 2020-02-24, Monday](#id-section31)
* [Entry 32: 2020-02-25, Tuesday](#id-section32)
* [Entry 33: 2020-02-26, Wednesday](#id-section33)
* [Entry 34: 2020-02-27, Thursday](#id-section34)
* [Entry 35: 2020-02-28, Friday](#id-section35)
* [Entry 36: 2020-03-02, Monday](#id-section36)
* [Entry 37: 2020-03-03, Tuesday](#id-section37)
* [Entry 38: 2020-03-04, Wednesday](#id-section38)
* [Entry 39: 2020-03-05, Thursday](#id-section39)
* [Entry 40: 2020-03-06, Friday](#id-section40)
* [Entry 41: 2020-03-09, Monday](#id-section41)
* [Entry 42: 2020-03-10, Tuesday](#id-section42)
* [Entry 43: 2020-03-11, Wednesday](#id-section43)
* [Entry 44: 2020-03-12, Thursday](#id-section44)
* [Entry 45: 2020-03-13, Friday](#id-section45)
* [Entry 46: 2020-03-16, Monday](#id-section46)
* [Entry 47: 2020-03-17, Tuesday](#id-section47)
* [Entry 48: 2020-03-18, Wednesday](#id-section48)
* [Entry 49: 2020-03-19, Thursday](#id-section49)
* [Entry 50: 2020-03-20, Friday](#id-section50)
* [Entry 51: 2020-03-23, Monday](#id-section51)
* [Entry 52: 2020-03-24, Tuesday](#id-section52)
* [Entry 53: 2020-03-25, Wednesday](#id-section53)
* [Entry 54: 2020-03-26, Thursday](#id-section54)
* [Entry 55: 2020-03-27, Friday](#id-section55)
* [Entry 56: 2020-03-30, Monday](#id-section56)
* [Entry 57: 2020-03-31, Tuesday](#id-section57)
* [Entry 58: 2020-04-01, Wednesday](#id-section58)
* [Entry 59: 2020-04-02, Thursday](#id-section59)
* [Entry 60: 2020-04-03, Friday](#id-section60)
* [Entry 61: 2020-04-06, Monday](#id-section61)
* [Entry 62: 2020-04-07, Tuesday](#id-section62)
* [Entry 63: 2020-04-08, Wednesday](#id-section63)
* [Entry 64: 2020-04-09, Thursday](#id-section64)
* [Entry 65: 2020-04-10, Friday](#id-section65)
* [Entry 66: 2020-04-13, Monday](#id-section66)
* [Entry 67: 2020-04-14, Tuesday](#id-section67)
* [Entry 68: 2020-04-15, Wednesday](#id-section68)
* [Entry 69: 2020-04-16, Thursday](#id-section69)
* [Entry 70: 2020-04-17, Friday](#id-section70)
* [Entry 71: 2020-04-20, Monday](#id-section71)
* [Entry 72: 2020-04-21, Tuesday](#id-section72)
* [Entry 73: 2020-04-22, Wednesday](#id-section73)
* [Entry 74: 2020-04-23, Thursday](#id-section74)
* [Entry 75: 2020-04-24, Friday](#id-section75)
* [Entry 76: 2020-04-27, Monday](#id-section76)
* [Entry 77: 2020-04-28, Tuesday](#id-section77)
* [Entry 78: 2020-04-29, Wednesday](#id-section78)
* [Entry 79: 2020-04-30, Thursday](#id-section79)
* [Entry 80: 2020-05-01, Friday](#id-section80)
* [Entry 81: 2020-05-04, Monday](#id-section81)
* [Entry 82: 2020-05-05, Tuesday](#id-section82)
* [Entry 83: 2020-05-06, Wednesday](#id-section83)
* [Entry 84: 2020-05-07, Thursday](#id-section84)
* [Entry 85: 2020-05-08, Friday](#id-section85)

------
<div id='id-section1'/>
### Entry 1: 2020-01-13, Monday.



------
<div id='id-section2'/>
### Entry 2: 2020-01-14, Tuesday.



------
<div id='id-section3'/>
### Entry 3: 2020-01-15, Wednesday.







------
<div id='id-section4'/>
### Entry 4: 2020-01-16, Thursday.



------
<div id='id-section5'/>
### Entry 5: 2020-01-17, Friday.



------
<div id='id-section6'/>
### Entry 6: 2020-01-20, Monday.



------
<div id='id-section7'/>
### Entry 7: 2020-01-21, Tuesday.



------
<div id='id-section8'/>
### Entry 8: 2020-01-22, Wednesday.

# Introduction to connecting to the Unix server bash command line, and our data set

## Using the Class Server
  + we will use a server called pbio381 to store our very large data sets
  + we can connect to it via Unix using a secure shell protocol while on campus
  + to do this, I would type in git bash the following:
    + ssh aehall@pbio381.uvm.edu
      + doing this will promt us to enter our uvm net id and password

## Basic Commands
  +  `pwd` allows you to see the path to your current directory type
    + you can use this to copy and paste your directory when you need it for
    reference while coding
  +  `cd` refers to changing directory use this command when you want
      to change your working directory. You can use it to start typing a directory
      you want to move into then press tab to complete.
    + my folder that is connected to my github can be entered by typing this:
      + `$ cd Documents/UVM/EcologicalGenomics/EcologicalGenomics`
      + to back up to just the first EcologicalGenomics folder you can enter `cd ..
  + `ll` allows you to view contents of a folder
  + `mkdir` creates a new folder
    + to name this folder aehfiles I would type `mkdir aehfiles`
    + if I did this while in the second EcologicalGenomics folder that's where
    the folder called aehfiles would live
  + `head n- # filename` will show you the first # lines of Data
  + `tail -n #filename` shows the # last lines of Data
  + `mv document.txt AlisonWork/Example` would move a document called document
  into the folder Example which lives in the folder AlisonWork
  + `rm document.txt` removes that file

## Red Spruce Data Set (*Picea rubens*)
  + the data set is part of an NSF project on population genomics of climate adaptation
  + over the course of the semester we will analyze exome-capture illumina data
  + data were collected by the Keller Lab from across the Appalachian Mountains
  ranging from Tennessee, USA to New Brunswick, CA.
  + Region- refers to the geographical and genetic cluster each ind. belongs to
    + Core(C), Margin (M), or Edge(E)
    + we will just focus on the *Edge*

## Data Storage:
      + `cd /data/project_data/RS_ExomeSeq`
      + `fastq` contains paired end illumina seq files
      + `metadata` folder has the `RS_Exome_metadata.txt` file
        + we won't edit this, because editing this will share our edits with the group
        + copy this folder and put it in your `mydata` (which we created to exist my EcologicalGenomics folder)
        + `cp RS_ExomeSeq.txt ~/<EcologicalGenomics>/mydata/`
      + use grep to select just the edge populations and move them to a new folder
        + do this from within the my data folder
          + `grep -w "E" RS_Exome_metadata.txt >Edge_only.txt`
            + grep- searches for data that match a term of interest
            + -w tells grep what that term of interest is. In this case only terms that match E as-is
            + `>` pipes to a new text file called Edge_only
            + learn more about grep by typing `mangrep` which will show you the manual

## Editing files in Unix
  + `vim .bash` to edit a bash file
  + `i` to insert into this file
  + click esc to leave edit mode
  + `:wq` to save changes and quit

## Git Command Line Push and Pull
  + `git status`
  + `git add --all` or `git -A`
  + `git status` again to make sure all previously red text documents are in green
  + `git commit -m"type message here within quotes"`
  + `git push` to push to online repo









------
<div id='id-section9'/>
### Entry 9: 2020-01-23, Thursday.



------
<div id='id-section10'/>
### Entry 10: 2020-01-24, Friday.



------
<div id='id-section11'/>
### Entry 11: 2020-01-27, Monday.



------
<div id='id-section12'/>
### Entry 12: 2020-01-28, Tuesday.



------
<div id='id-section13'/>
### Entry 13: 2020-01-29, Wednesday.

# Population Genomics Day 1

## More about Red Spruce
  + coniferous tree that plays a prominent role in montane communities throughout the Appalachians. Thrives in cool, moist climates of the high elevation mountains
  +"island" populations exit on mountaintops are in low latitude trailing edge of the range spanning from Maryland to Tennessee
  + these are remnant populations of spruce. The trees retreated to the mountain top refugia as the climate warmed.
  + this caused them to be highly isolated from other stands
  + out project aims to understand the genetic resource represented by these fragmented edge populations
  + Main goals of this project in the Keller Lab
    1. characterize genetic diversity and pop structuer across range
    2. identify regions of the genome that show evidence of positive selection in response to climate gradients
    3. map the genetic basis of climate adaptive phenotypes
  + Using this information we can inform areas of the range that are most likely to experience climate maladaptation and help guide mitigation strategies
  + This [link](https://pespenilab.github.io/Ecological-Genomics/2020-01-29_PopGenomics_Day1.html) to information provided about design from Steve's tutorial

## Basic Coding Pipeline
  1. Visualize using FastQC. This is a quality control tool for high throughput sequence data.
  It is used on raw sequence data and provides a modular set of analyses that gives a quick impression on any large problems with your data. It can be used to uncover biases in data that can affect how you could use it.
  Unlike the QC report provided by a sequencer, FastQC's report spots problems that originnate either in the sequencer or in the starting library material.
  2. Clean the data with Trimmomatic. Trimmomatic performs trimming for the illumina specific sequences, and uses a sliding window approach ot trimp. It travels along the tread and cuts where quality falls below a certain specified treshold. It will cut the reads to a specific length and works with FastQC
  3. After this you'll visualize again with FastQC
  4. Then calculate the numbers of cleaned, high quality reads that go into mapping
  5. Align these cleaned reads from each sample to the reference assembly to generate sequence alignment filesusing bwa. Files go in as .fastqc and out as .sam
  6. Remove PCR duplicates and calculate alignment statistics(% reads mapped successfully, mapping quality scores, and average depth of coverage per individual)

### New code learned today:
  + `zcat` like `head` for compressed files. FastQC files are big, so big that they must be compressed we can't use `head` on a compressed file.
  to peek inside a compressed file while keeping it compressed use the `zcat`
    + example of how I used this:
      + data are located here: `cd /data/project_data/RS_ExomeSeq/fastq/edge_fastq`
      + `zcat XWS_05_R1_fastq.gz | head -n 4` to see the first 4 lines of my files
  +


*Note: I used the population XWS for my analysis*







------
<div id='id-section14'/>
### Entry 14: 2020-01-30, Thursday.

zcat allows you to peek inside a gz file
use head -n4 to see first 4 lines in the file that you have selected
then you'll see an @ sign and then the information about the computer that it came from. Then come the barcodes that idenfiy the sequence
second line is the read
N represents any base
third line is the seperator between the second and forth
fourth line is the code that shows how confident are we that we read the line correctly


Ill be working with the XWS

------
<div id='id-section15'/>
### Entry 15: 2020-01-31, Friday.



------
<div id='id-section16'/>
### Entry 16: 2020-02-03, Monday.



------
<div id='id-section17'/>
### Entry 17: 2020-02-04, Tuesday.



------
<div id='id-section18'/>
### Entry 18: 2020-02-05, Wednesday.



------
<div id='id-section19'/>
### Entry 19: 2020-02-06, Thursday.



------
<div id='id-section20'/>
### Entry 20: 2020-02-07, Friday.



------
<div id='id-section21'/>
### Entry 21: 2020-02-10, Monday.



------
<div id='id-section22'/>
### Entry 22: 2020-02-11, Tuesday.



------
<div id='id-section23'/>
### Entry 23: 2020-02-12, Wednesday.



------
<div id='id-section24'/>
### Entry 24: 2020-02-13, Thursday.



------
<div id='id-section25'/>
### Entry 25: 2020-02-14, Friday.



------
<div id='id-section26'/>
### Entry 26: 2020-02-17, Monday.



------
<div id='id-section27'/>
### Entry 27: 2020-02-18, Tuesday.



------
<div id='id-section28'/>
### Entry 28: 2020-02-19, Wednesday.



------
<div id='id-section29'/>
### Entry 29: 2020-02-20, Thursday.



------
<div id='id-section30'/>
### Entry 30: 2020-02-21, Friday.



------
<div id='id-section31'/>
### Entry 31: 2020-02-24, Monday.



------
<div id='id-section32'/>
### Entry 32: 2020-02-25, Tuesday.



------
<div id='id-section33'/>
### Entry 33: 2020-02-26, Wednesday.



------
<div id='id-section34'/>
### Entry 34: 2020-02-27, Thursday.



------
<div id='id-section35'/>
### Entry 35: 2020-02-28, Friday.



------
<div id='id-section36'/>
### Entry 36: 2020-03-02, Monday.



------
<div id='id-section37'/>
### Entry 37: 2020-03-03, Tuesday.



------
<div id='id-section38'/>
### Entry 38: 2020-03-04, Wednesday.



------
<div id='id-section39'/>
### Entry 39: 2020-03-05, Thursday.



------
<div id='id-section40'/>
### Entry 40: 2020-03-06, Friday.



------
<div id='id-section41'/>
### Entry 41: 2020-03-09, Monday.



------
<div id='id-section42'/>
### Entry 42: 2020-03-10, Tuesday.



------
<div id='id-section43'/>
### Entry 43: 2020-03-11, Wednesday.



------
<div id='id-section44'/>
### Entry 44: 2020-03-12, Thursday.



------
<div id='id-section45'/>
### Entry 45: 2020-03-13, Friday.



------
<div id='id-section46'/>
### Entry 46: 2020-03-16, Monday.



------
<div id='id-section47'/>
### Entry 47: 2020-03-17, Tuesday.



------
<div id='id-section48'/>
### Entry 48: 2020-03-18, Wednesday.



------
<div id='id-section49'/>
### Entry 49: 2020-03-19, Thursday.



------
<div id='id-section50'/>
### Entry 50: 2020-03-20, Friday.



------
<div id='id-section51'/>
### Entry 51: 2020-03-23, Monday.



------
<div id='id-section52'/>
### Entry 52: 2020-03-24, Tuesday.



------
<div id='id-section53'/>
### Entry 53: 2020-03-25, Wednesday.



------
<div id='id-section54'/>
### Entry 54: 2020-03-26, Thursday.



------
<div id='id-section55'/>
### Entry 55: 2020-03-27, Friday.



------
<div id='id-section56'/>
### Entry 56: 2020-03-30, Monday.



------
<div id='id-section57'/>
### Entry 57: 2020-03-31, Tuesday.



------
<div id='id-section58'/>
### Entry 58: 2020-04-01, Wednesday.



------
<div id='id-section59'/>
### Entry 59: 2020-04-02, Thursday.



------
<div id='id-section60'/>
### Entry 60: 2020-04-03, Friday.



------
<div id='id-section61'/>
### Entry 61: 2020-04-06, Monday.



------
<div id='id-section62'/>
### Entry 62: 2020-04-07, Tuesday.



------
<div id='id-section63'/>
### Entry 63: 2020-04-08, Wednesday.



------
<div id='id-section64'/>
### Entry 64: 2020-04-09, Thursday.



------
<div id='id-section65'/>
### Entry 65: 2020-04-10, Friday.



------
<div id='id-section66'/>
### Entry 66: 2020-04-13, Monday.



------
<div id='id-section67'/>
### Entry 67: 2020-04-14, Tuesday.



------
<div id='id-section68'/>
### Entry 68: 2020-04-15, Wednesday.



------
<div id='id-section69'/>
### Entry 69: 2020-04-16, Thursday.



------
<div id='id-section70'/>
### Entry 70: 2020-04-17, Friday.



------
<div id='id-section71'/>
### Entry 71: 2020-04-20, Monday.



------
<div id='id-section72'/>
### Entry 72: 2020-04-21, Tuesday.



------
<div id='id-section73'/>
### Entry 73: 2020-04-22, Wednesday.



------
<div id='id-section74'/>
### Entry 74: 2020-04-23, Thursday.



------
<div id='id-section75'/>
### Entry 75: 2020-04-24, Friday.



------
<div id='id-section76'/>
### Entry 76: 2020-04-27, Monday.



------
<div id='id-section77'/>
### Entry 77: 2020-04-28, Tuesday.



------
<div id='id-section78'/>
### Entry 78: 2020-04-29, Wednesday.



------
<div id='id-section79'/>
### Entry 79: 2020-04-30, Thursday.



------
<div id='id-section80'/>
### Entry 80: 2020-05-01, Friday.



------
<div id='id-section81'/>
### Entry 81: 2020-05-04, Monday.



------
<div id='id-section82'/>
### Entry 82: 2020-05-05, Tuesday.



------
<div id='id-section83'/>
### Entry 83: 2020-05-06, Wednesday.



------
<div id='id-section84'/>
### Entry 84: 2020-05-07, Thursday.



------
<div id='id-section85'/>
### Entry 85: 2020-05-08, Friday.
